{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_PATH = \"embeddings\"\n",
    "LANGUAGES = [\"java\", \"javascript\", \"php\", \"python\"]\n",
    "MODEL = \"codet5\"\n",
    "EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_embeddings(lang: str):\n",
    "    lang_embedding_path = os.path.join(EMBEDDING_PATH, MODEL, lang)\n",
    "    filenames = os.listdir(lang_embedding_path)\n",
    "\n",
    "    for filename in filenames:\n",
    "        yield torch.load(os.path.join(lang_embedding_path, filename), map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_embedding(lang: str):\n",
    "    n = 0\n",
    "    accum = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    for embedding in stream_embeddings(lang):\n",
    "        accum += embedding\n",
    "        n += 1\n",
    "    \n",
    "    return accum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings: dict[str, torch.Tensor] = dict()\n",
    "for lang in LANGUAGES:\n",
    "    mean_embeddings[lang] = calculate_mean_embedding(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(lang2embedding: dict[str, torch.Tensor]):\n",
    "    langs = list(lang2embedding.keys())\n",
    "    num_langs = len(langs)\n",
    "    sim_matrix = torch.empty((num_langs, num_langs))\n",
    "\n",
    "    for i in range(num_langs):\n",
    "        for j in range(i, num_langs):\n",
    "            if i == j: sim_matrix[i][j] = 1\n",
    "\n",
    "            lang1 = langs[i]\n",
    "            lang2 = langs[j]\n",
    "\n",
    "            similarity = torch.nn.functional.cosine_similarity(lang2embedding[lang1], lang2embedding[lang2], dim = 0)\n",
    "            sim_matrix[i][j] = similarity\n",
    "            sim_matrix[j][i] = similarity\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = calculate_similarity_matrix(mean_embeddings)\n",
    "\n",
    "print(list(mean_embeddings.keys()))\n",
    "print(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mean_embeddings, \"codet5_mean_embeddings.dict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
